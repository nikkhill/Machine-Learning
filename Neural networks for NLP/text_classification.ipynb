{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFPxHyLgLh71",
    "colab_type": "text"
   },
   "source": [
    "# Download dataset, build vocabulary and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JRClj5Fmm8dW",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!wget http://phontron.com/data/topicclass-v1.tar.gz\n",
    "!tar -xvf topicclass-v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "CZ3Pu6GunK52",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "jFuTyfqFnOsz",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class Voc:\n",
    "    def __init__(self):\n",
    "        self.w2i = defaultdict(lambda: len(self.w2i))\n",
    "        self.wcounts = defaultdict(lambda: 0)\n",
    "        self.PAD = self.w2i[\"<pad>\"]\n",
    "        self.UNK = self.w2i[\"<unk>\"]\n",
    "        self.char2i = defaultdict(lambda: len(self.char2i))\n",
    "        self.PADCHAR = self.char2i[\"<pad>\"]\n",
    "        self.UNKCHAR = self.char2i[\"<unk>\"]\n",
    "        self.char_vocab_len = len(self.char2i)\n",
    "\n",
    "    def add_sentence(self, line):\n",
    "        # returns list of indices\n",
    "        line = line.strip()\n",
    "        words = []\n",
    "        for w in line.split():\n",
    "            lower_w = w.lower()\n",
    "            words.append(self.w2i[lower_w])\n",
    "            [self.char2i[c] for c in w]\n",
    "            self.wcounts[lower_w] += 1\n",
    "        return words\n",
    "\n",
    "    def return_indices(self, line):\n",
    "        line = line.strip()\n",
    "        words = []\n",
    "        words_char_level = []\n",
    "        for w in line.split():\n",
    "            lower_w = w.lower()\n",
    "            if lower_w in self.w2i:\n",
    "                words.append(self.w2i[lower_w])\n",
    "            else:\n",
    "                words.append(self.UNK)\n",
    "            chars = []\n",
    "            for c in w:\n",
    "                if c in self.char2i:\n",
    "                    chars.append(self.char2i[c])\n",
    "                else:\n",
    "                    chars.append(self.UNKCHAR)\n",
    "            words_char_level.append(np.array(chars))\n",
    "        return np.array(words), np.array(words_char_level)\n",
    "\n",
    "    def trim(self, min_count):\n",
    "        to_keep = []\n",
    "        for w in self.wcounts:\n",
    "            if self.wcounts[w] >= min_count:\n",
    "                to_keep.append(w)\n",
    "        self.w2i = {}\n",
    "        self.w2i = defaultdict(lambda: len(self.w2i))\n",
    "        self.wcounts_updated = defaultdict(lambda: 0)\n",
    "        self.PAD = self.w2i[\"<pad>\"]\n",
    "        self.UNK = self.w2i[\"<unk>\"]\n",
    "        for w in to_keep:\n",
    "            self.w2i[w]\n",
    "            self.wcounts_updated[w] = self.wcounts[w]\n",
    "        self.wcounts = self.wcounts_updated\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.w2i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6q0KMVljnPJ6",
    "colab_type": "code",
    "outputId": "716485a1-11cc-40ca-cd56-c7eb3e2b2482",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120634\n"
     ]
    }
   ],
   "source": [
    "train_file = 'topicclass/topicclass_train.txt'\n",
    "dev_file = 'topicclass/topicclass_valid.txt'\n",
    "test_file = 'topicclass/topicclass_test.txt'\n",
    "\n",
    "voc = Voc()\n",
    "\n",
    "def build_vocab(file):\n",
    "    # initial processing to be done on training set for building the vocab\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            _, line = line.split('|||')\n",
    "            voc.add_sentence(line)\n",
    "\n",
    "def load_data(file):\n",
    "    # this processes sentences and returns data in required format\n",
    "    out = []\n",
    "    topics = set()\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            topic, line = line.split('|||')\n",
    "            topic = topic.strip()\n",
    "            words, words_char_level = voc.return_indices(line)\n",
    "            out.append((topic, words_char_level, words))\n",
    "            topics.add(topic)\n",
    "    return out, topics\n",
    "\n",
    "build_vocab(train_file)\n",
    "print(len(voc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "k2lEcLbcnRcZ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# voc.trim(5)\n",
    "# len(voc)\n",
    "nwords = len(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "HqQEsvhAnTPQ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "train_data, train_topics = load_data(train_file)\n",
    "dev_data, dev_topics = load_data(dev_file)\n",
    "all_topics = train_topics.union(dev_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "kRl-l8tinWuh",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "topic_to_idx = {topic: idx for (idx, topic) in enumerate(all_topics)}\n",
    "idx_to_topic = {idx: topic for (topic, idx) in topic_to_idx.items()}\n",
    "ntags = len(topic_to_idx)\n",
    "# idx_to_topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Crg6MWUKnbk3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class SentencesDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # returns a tuple (words, words_char_level, labels\n",
    "        sample = (torch.from_numpy(self.data[idx][2]),\n",
    "                  torch.nn.utils.rnn.pad_sequence([torch.from_numpy(x) for x in self.data[idx][1]], batch_first=True)\n",
    "                  , topic_to_idx[self.data[idx][0]])\n",
    "        return sample\n",
    "\n",
    "def pad_vect(vect, pad_len, dim):\n",
    "    # vec padded to pad in dimension dim\n",
    "    pad_amount = list(vect.shape)\n",
    "    pad_amount[dim] = pad_len - vect.size(dim)\n",
    "    padded = torch.cat([vect, torch.zeros(*pad_amount).long()], dim=dim)\n",
    "    return padded\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # takes a list of (tensor, label), returns padded examples and labels\n",
    "    # find longest sentence\n",
    "    dim = 0\n",
    "    max_len = max(map(lambda x: x[0].shape[dim], batch))\n",
    "    max_word_len = max(map(lambda x: x[1].shape[1], batch))\n",
    "    batch = list(map(lambda d: (pad_vect(d[0], pad_len=max_len, dim=dim),\n",
    "                                pad_vect(pad_vect(d[1], pad_len=max_word_len, dim=1), pad_len=max_len, dim=dim), d[2]),\n",
    "                     batch))\n",
    "    ws = torch.stack(list(map(lambda x: x[0], batch)), dim=0)\n",
    "    cs = torch.stack(list(map(lambda x: x[1], batch)), dim=0)\n",
    "    ys = torch.LongTensor(list(map(lambda x: x[2], batch)))\n",
    "    return ws, cs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rfSwGT9MDopl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "train_samples = SentencesDataset(train_data)\n",
    "dataloader_args = dict(shuffle=True, batch_size=512, num_workers=10, pin_memory=True, collate_fn=collate_fn) if cuda \\\n",
    "    else dict(shuffle=False, batch_size=64, collate_fn=collate_fn)\n",
    "train_loader = dataloader.DataLoader(train_samples, **dataloader_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "t7A_lcgBnjMK",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    # runs the training\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    run_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    for batch_num, sample in enumerate(train_loader):\n",
    "        if batch_num % 100 == 0:\n",
    "            print(\".\", end='')\n",
    "        optimizer.zero_grad()\n",
    "        data_words = sample[0].to(device)\n",
    "        data_chars = sample[1].to(device)\n",
    "        target = sample[2].to(device)\n",
    "\n",
    "        output = model(data_words, data_chars)\n",
    "        _, predictions = torch.max(output.data, 1)\n",
    "        correct_predictions += (predictions == target).sum().item()\n",
    "        total_predictions += target.size(0)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        run_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    accuracy = correct_predictions * 100 / total_predictions \n",
    "    run_loss /= len(train_loader)\n",
    "    print('\\nTrain Loss: ', run_loss, '| Train Accuracy: ', accuracy, '%', '| Time: ', end_time - start_time, 's')\n",
    "    return run_loss, accuracy\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, criterion):\n",
    "    # runs validation, calculates accuracy and loss\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "\n",
    "        run_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for sample in test_loader:\n",
    "            data_words = sample[0].to(device)\n",
    "            data_chars = sample[1].to(device)\n",
    "            target = sample[2].to(device)\n",
    "\n",
    "            output = model(data_words, data_chars)\n",
    "            _, predictions = torch.max(output.data, 1)\n",
    "            correct_predictions += (predictions == target).sum().item()\n",
    "            total_predictions += target.size(0)\n",
    "\n",
    "            loss = criterion(output, target).detach()\n",
    "            run_loss += loss.item()\n",
    "\n",
    "        accuracy = correct_predictions * 100 / total_predictions \n",
    "        run_loss /= len(test_loader)\n",
    "        print('Test Loss: ', run_loss, '| Test Accuracy: ', accuracy, '%')\n",
    "        return run_loss, accuracy\n",
    "\n",
    "    \n",
    "def output_results(model, test_loader):\n",
    "    # the output predictions for test\n",
    "    output = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        for sample in test_loader:\n",
    "            data_words = sample[0].to(device)\n",
    "            data_chars = sample[1].to(device)\n",
    "            outputs = model(data_words, data_chars)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            output.extend(predicted.cpu().numpy())\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQAJRcEzWs6d",
    "colab_type": "text"
   },
   "source": [
    "# Pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gW-X-yfnXNJq",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353.0
    },
    "outputId": "7a64c9e4-3031-4195-f336-3b0ce7e9bde2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-02-15 16:11:33--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2019-02-15 16:11:33--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  7.93MB/s    in 1m 42s  \n",
      "\n",
      "2019-02-15 16:13:15 (8.08 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "p0UrQ-HuV5cz",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from emb_weights import EmbWeights\n",
    "\n",
    "ew = EmbWeights(r\"glove.6B.200d.txt\")\n",
    "emb_mat = ew.create_emb_matrix(voc.w2i)\n",
    "# print(emb_mat)\n",
    "emb_mat = torch.tensor(emb_mat).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-9eG-i6MHxL",
    "colab_type": "text"
   },
   "source": [
    "# Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "A5yLdssL-IUY",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(3)\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "l2_2yrMMnY4Z",
    "colab_type": "code",
    "outputId": "1087b7e4-ca30-4455-f390-f044875f419e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (char_emb): Embedding(2312, 20, padding_idx=0)\n",
      "  (emb): Embedding(120634, 200)\n",
      "  (cnn_char): Conv1d(20, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (gru_emb): GRU(232, 100, num_layers=2, bidirectional=True)\n",
      "  (conv3): Conv1d(200, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (mpool3): MaxPool1d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (dense_layer): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (projection_layer): Linear(in_features=128, out_features=17, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n",
      "number of trainable parameters: 815601\n"
     ]
    }
   ],
   "source": [
    "EMB_SIZE = 200\n",
    "CHAR_EMB_SIZE = 20\n",
    "CHAR_CNN_FILTER_SIZE = 32\n",
    "RNN_EMB_SIZE = 200\n",
    "WIN_SIZE = 3\n",
    "FILTER_SIZE_3 = 256\n",
    "FILTER_SIZE_4 = 256\n",
    "DENSE_SIZE = 128\n",
    "\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.char_emb = nn.Embedding(len(voc.char2i), CHAR_EMB_SIZE, padding_idx=voc.PADCHAR)\n",
    "        self.emb = nn.Embedding.from_pretrained(emb_mat, freeze=True, sparse=False)\n",
    "\n",
    "        self.cnn_char = torch.nn.Conv1d(in_channels=CHAR_EMB_SIZE, out_channels=CHAR_CNN_FILTER_SIZE, kernel_size=3,\n",
    "                                        stride=1, padding=3 // 2, dilation=1, groups=1, bias=True)\n",
    "\n",
    "        self.gru_emb = torch.nn.GRU(input_size=EMB_SIZE + CHAR_CNN_FILTER_SIZE, hidden_size=RNN_EMB_SIZE // 2,\n",
    "                                    num_layers=2, bidirectional=True)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv1d(in_channels=RNN_EMB_SIZE, out_channels=FILTER_SIZE_3, kernel_size=WIN_SIZE,\n",
    "                                     stride=2, padding=WIN_SIZE // 2, dilation=1, groups=1, bias=True)\n",
    "        self.mpool3 = nn.MaxPool1d(WIN_SIZE, padding=WIN_SIZE // 2)\n",
    "\n",
    "        self.conv4 = torch.nn.Conv1d(in_channels=FILTER_SIZE_3, out_channels=FILTER_SIZE_4, kernel_size=WIN_SIZE,\n",
    "                                     stride=2, padding=WIN_SIZE // 2, dilation=1, groups=1, bias=True)\n",
    "        #         self.gru = torch.nn.GRU(input_size=FILTER_SIZE_3, hidden_size=200, num_layers=2, bidirectional=True)\n",
    "        self.dense_layer = torch.nn.Linear(in_features=FILTER_SIZE_4, out_features=DENSE_SIZE, bias=True)\n",
    "        self.projection_layer = torch.nn.Linear(in_features=DENSE_SIZE, out_features=ntags, bias=True)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def forward(self, words, word_chars):\n",
    "        # char:\n",
    "        batch_size, max_len, max_wlen = word_chars.shape\n",
    "        ce = self.char_emb(word_chars)  # e.g. 2, 55, 11, 10\n",
    "        ce = ce.permute(0, 1, 3, 2)\n",
    "        c = self.cnn_char(ce.view(-1, CHAR_EMB_SIZE, max_wlen))\n",
    "        c = c.view(batch_size, max_len, CHAR_CNN_FILTER_SIZE, max_wlen)\n",
    "        c = c.max(dim=3)[0]\n",
    "        c = F.relu(c)  # c is batch x nwords x filter_size\n",
    "        c = c.permute(0, 2, 1)\n",
    "\n",
    "        emb = self.emb(words)  # batch x nwords x emb_size\n",
    "        emb = emb.permute(0, 2, 1)  # batch x emb_size x nwords\n",
    "\n",
    "        combined_emb = torch.cat((emb, c), 1)\n",
    "        combined_emb = combined_emb.permute(2, 0, 1)\n",
    "        combined_emb, _ = self.gru_emb(\n",
    "            combined_emb)  # improved embeddings, out: (seq_len, batch, num_directions * hidden_size)\n",
    "        combined_emb = combined_emb.permute(1, 2, 0)  # batch x rnn_emb_size x nwords\n",
    "        h = combined_emb\n",
    "\n",
    "        h = self.conv3(h)  # batch x num_filters x nwords\n",
    "        h = self.mpool3(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv4(h)  # output is (batch, Channels, outseqlen)\n",
    "        h = h.max(dim=2)[0]  # batch x num_filters\n",
    "        h = F.relu(h)\n",
    "        h = self.dense_layer(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.dropout(h)\n",
    "        out = self.projection_layer(h)  # size(out) = batch x ntags   \n",
    "        return out\n",
    "\n",
    "\n",
    "model = CNNClassifier()\n",
    "print(model)\n",
    "print(\"number of trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-8wqXuc5ngY3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ek_6SlD1ndg4",
    "colab_type": "code",
    "outputId": "417309d9-9ad9-4b5b-f131-7df28bcfc559",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253909, 643)"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples = SentencesDataset(train_data)\n",
    "dev_samples = SentencesDataset(dev_data)\n",
    "train_dataloader_args = dict(shuffle=True, batch_size=256, pin_memory=True, collate_fn=collate_fn) if cuda \\\n",
    "    else dict(shuffle=False, batch_size=64, collate_fn=collate_fn)\n",
    "train_loader = dataloader.DataLoader(train_samples, **train_dataloader_args)\n",
    "\n",
    "test_dataloader_args = dict(shuffle=True, batch_size=64, pin_memory=True, collate_fn=collate_fn) if cuda \\\n",
    "    else dict(shuffle=False, batch_size=64, collate_fn=collate_fn)\n",
    "dev_loader = dataloader.DataLoader(dev_samples, **test_dataloader_args)\n",
    "# len(dev_loader)\n",
    "len(train_samples), len(dev_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3EoUf22xnlLG",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "D6zNRBMInm3s",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "for i in range(n_epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, dev_loader, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "    train_accs.append(train_acc)\n",
    "    if len(test_accs) > 1 and test_acc < max(test_accs):\n",
    "        print(\"val acc decreased\")\n",
    "    else:\n",
    "        torch.save(model.state_dict(), \"test_saved_model_edit\")\n",
    "    print('-' * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "Zhxu1qB-00xk",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50.0
    },
    "outputId": "a575637f-069d-4a3a-da39-0cfd184099f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.9503031508489088 | Test Accuracy:  82.89269051321928 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9503031508489088, 82.89269051321928)"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"test_saved_model_edit\"))\n",
    "test_model(model, dev_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "43fkm5qd_6E8",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# model3 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "X_P-C254ZVvg",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# torch.save(model1.state_dict(), \"test_saved_model_edit1\")\n",
    "# torch.save(model2.state_dict(), \"test_saved_model_edit2\")\n",
    "# torch.save(model3.state_dict(), \"test_saved_model_edit3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "nfEguLu4ZgRK",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"vocc2i\", 'w') as vf:\n",
    "#     json.dump(voc.char2i, vf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "d4mCyT8LvwMo",
    "colab_type": "code",
    "outputId": "043e4094-8fd6-49c4-f8e9-1bc02c0040b1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.911701401187615 | Test Accuracy:  84.13685847589424 %\n",
      "Test Loss:  1.0424332103945992 | Test Accuracy:  82.73716951788491 %\n",
      "Test Loss:  1.047897850925272 | Test Accuracy:  82.89269051321928 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.047897850925272, 82.89269051321928)"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model1, dev_loader, criterion)\n",
    "test_model(model2, dev_loader, criterion)\n",
    "test_model(model3, dev_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ncJ00rLH5T4-",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "test_data, test_topics = load_data(test_file)\n",
    "test_samples = SentencesDataset(test_data)\n",
    "\n",
    "predict_dataloader_args = dict(shuffle=False, batch_size=64, pin_memory=True, collate_fn=collate_fn) if cuda \\\n",
    "    else dict(shuffle=False, batch_size=64, collate_fn=collate_fn)\n",
    "test_loader = dataloader.DataLoader(test_samples, **predict_dataloader_args)\n",
    "dev_predict_loader = dataloader.DataLoader(dev_samples, **predict_dataloader_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XGqWqSA86HCC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "output = output_results(model, dev_predict_loader)\n",
    "output_file = \"valid_predictions_3.txt\"\n",
    "with open(output_file, 'w') as of:\n",
    "    for i in range(len(output)):\n",
    "        of.write(\"{}\\n\".format(idx_to_topic[output[i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JgUruyYt963x",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "topic_to_idx['UNK'] = -1\n",
    "output = output_results(model, test_loader)\n",
    "output_file = \"test_predictions_3.txt\"\n",
    "with open(output_file, 'w') as of:\n",
    "    for i in range(len(output)):\n",
    "        of.write(\"{}\\n\".format(idx_to_topic[output[i]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX_oxnSwEv16",
    "colab_type": "text"
   },
   "source": [
    "# Ensemble using majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "KgcphWaAJT_E",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def read_result(filename):\n",
    "    out = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            label = line.strip()\n",
    "            out.append(label)\n",
    "    return out\n",
    "\n",
    "r1 = read_result(\"test_predictions_3.txt\")\n",
    "r2 = read_result(\"test_predictions_2.txt\")\n",
    "rbest = read_result(\"test_predictions_1.txt\")\n",
    "# r1 = read_result(\"valid_predictions_3.txt\")\n",
    "# r2 = read_result(\"valid_predictions_2.txt\")\n",
    "# rbest = read_result(\"valid_predictions_1.txt\")\n",
    "\n",
    "with open(\"ensemble_results_test.csv\", \"w\") as wf:\n",
    "    for i in range(len(rbest)):\n",
    "        l1, l2, lb = r1[i], r2[i], rbest[i]\n",
    "        if l1 == l2:\n",
    "            l = l1\n",
    "        else:\n",
    "            l = lb\n",
    "        wf.write(\"{}\\n\".format(l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "U-M6woFWJ_9u",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "3a44dd9d-7dbe-43bd-80c9-8df444adc73c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 84.44790046656298\n"
     ]
    }
   ],
   "source": [
    "with open(dev_file) as df:\n",
    "    with open(\"ensemble_results_valid.csv\") as rf:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        dfl = df.readlines()\n",
    "        rfl = rf.readlines()\n",
    "        for i in range(len(dfl)):\n",
    "            if rfl[i].strip() == dfl[i].split('|||')[0].strip():\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Ensemble accuracy:\", correct/total*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebLCjio7P6gc",
    "colab_type": "text"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "SeUXQV8lP5pI",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "with open(\"topicclass_valid.txt\") as df:\n",
    "    with open(\"ensemble_results_valid.csv\") as rf:\n",
    "        dfl = df.readlines()\n",
    "        rfl = rf.readlines()\n",
    "expected =  [line.split('|||')[0].strip() for line in dfl]\n",
    "lines = [line.split('|||')[1].strip() for line in dfl]\n",
    "result = [t.strip() for t in rfl]\n",
    "correct = 0\n",
    "total = 0\n",
    "sent_lens = []\n",
    "wrong_sent_lens = []\n",
    "for i in range(len(dfl)):\n",
    "    if result[i] != expected[i]:\n",
    "        print(dfl[i])\n",
    "        print(rfl[i])\n",
    "        wrong_sent_lens.append(len(lines[i]))\n",
    "    else:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    sent_lens.append(len(lines[i]))\n",
    "print(\"Ensemble accuracy:\", correct/total*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Z5BYsH3cQ41j",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "topic_list = sorted(list(all_topics))\n",
    "print(topic_list)\n",
    "c = confusion_matrix(expected, result, labels=topic_list)\n",
    "np.savetxt(\"conf_mat.csv\", c, delimiter=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_classification.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
